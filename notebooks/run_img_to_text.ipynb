{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd06c083-255b-49d6-a052-4d7cec3101c3",
   "metadata": {},
   "source": [
    "# License Plate Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36423183-7ab7-492d-928f-6cde099c9805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: c:\\Users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: ultralytics in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (8.1.2)\n",
      "Requirement already satisfied: matplotlib>=3.3.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (3.8.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (5.9.7)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (1.11.4)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: opencv-python>=4.6.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (4.9.0.80)\n",
      "Requirement already satisfied: numpy>=1.22.2 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (1.26.3)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (2.1.2)\n",
      "Requirement already satisfied: pandas>=1.1.4 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (2.1.4)\n",
      "Requirement already satisfied: pillow>=7.1.2 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (10.2.0)\n",
      "Requirement already satisfied: thop>=0.1.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (0.1.1.post2209072238)\n",
      "Requirement already satisfied: requests>=2.23.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.64.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (4.66.1)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (0.13.1)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (0.16.2)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from ultralytics) (6.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (2.8.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (4.47.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (3.1.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (23.2)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.4.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib>=3.3.0->ultralytics) (1.2.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pandas>=1.1.4->ultralytics) (2023.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2023.11.17)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.23.0->ultralytics) (2.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from requests>=2.23.0->ultralytics) (3.6)\n",
      "Requirement already satisfied: sympy in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from torch>=1.8.0->ultralytics) (4.9.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2023.12.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.13.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tqdm>=4.64.0->ultralytics) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from sympy->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: c:\\Users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mltu in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (1.1.8)\n",
      "Requirement already satisfied: PyYAML>=6.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (6.0.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (2.1.4)\n",
      "Requirement already satisfied: numpy in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (1.26.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (3.8.2)\n",
      "Requirement already satisfied: onnxruntime>=1.15.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (1.16.3)\n",
      "Requirement already satisfied: Pillow>=9.4.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (10.2.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (4.9.0.80)\n",
      "Requirement already satisfied: tqdm in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from mltu) (4.66.1)\n",
      "Requirement already satisfied: protobuf in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from onnxruntime>=1.15.0->mltu) (3.20.3)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from onnxruntime>=1.15.0->mltu) (23.5.26)\n",
      "Requirement already satisfied: sympy in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from onnxruntime>=1.15.0->mltu) (1.12)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from onnxruntime>=1.15.0->mltu) (15.0.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from onnxruntime>=1.15.0->mltu) (23.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib->mltu) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib->mltu) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib->mltu) (1.4.5)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib->mltu) (4.47.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib->mltu) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from matplotlib->mltu) (3.1.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pandas->mltu) (2023.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from pandas->mltu) (2023.3.post1)\n",
      "Requirement already satisfied: colorama in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from tqdm->mltu) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->mltu) (1.16.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from coloredlogs->onnxruntime>=1.15.0->mltu) (10.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from sympy->onnxruntime>=1.15.0->mltu) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.15.0->mltu) (3.4.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "[notice] To update, run: c:\\Users\\avint\\.pyenv\\pyenv-win\\versions\\3.10.11\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# installing missing YOLO dependencies\n",
    "%pip install lapx>=0.5.2\n",
    "# installing OCR library\n",
    "%pip install ultralytics\n",
    "%pip install mltu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc138ca6",
   "metadata": {},
   "source": [
    "We are importing the following libraries:\n",
    "* **ast** for parsing the bounding boxes\n",
    "* **cv2** for video processing\n",
    "* **easyocr** for OCR\n",
    "* **glob** for finding files\n",
    "* **numpy** for array operations\n",
    "* **pandas** for dataframes\n",
    "* **string** for string operations\n",
    "* **ultralytics** for **YOLO** for object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49bc586b-9296-4595-bfac-bc67f084967f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import cv2 as cv\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from ultralytics import YOLO\n",
    "from mltu.inferenceModel import OnnxInferenceModel\n",
    "from mltu.utils.text_utils import ctc_decoder, get_cer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb43462-e19c-4d0c-957e-a0daf6b775ac",
   "metadata": {},
   "source": [
    "## License Plate Detection\n",
    "\n",
    "**YOLOv8** is capable of detecting cars, buses and trucks very easily without additional trainings from the dataset.It is already trained from the COCO dataset.But license number plates seem to be a bit harder. The model often confuses street signs or just basic backgound noise as a car registration plate. \n",
    "<br/>\n",
    "<br/>\n",
    "To make things more efficient, we are combining both models - a regular COCO trained YOLOv8 and our number plate detector.If the COCO model spots a car, we will then execute the number plate detector to focus its search within the area marked out by the first model's bounding box. That way, we are only seaarching for number plates when there is a car in the picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab07b17",
   "metadata": {},
   "source": [
    "This is a regular COCO trained YOLOv8 model for car detection.<br/>\n",
    "`coco_model = YOLO('yolov8n.pt')`\n",
    "\n",
    "This is our custom model trained on the License Plate Dataset.<br/>\n",
    "`np_model = YOLO('../model/runs/detect/train/weights/best.pt')`\n",
    "\n",
    "*best.pt* weight is produced by training our model with +21000 annoted images of license plates for 3 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd39fc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are mapping dictionaries for character conversion.\n",
    "# If we know that the first character in the number plate always is an string eg. `O` then if our OCR reader reads that O as `0` then it would be a mistake.\n",
    "# To prevent this we are mapping dictionaries with similar keys and values.\n",
    "\n",
    "dict_char_to_int = {'O': '0',\n",
    "                    'I': '1',\n",
    "                    'J': '3',\n",
    "                    'A': '4',\n",
    "                    'G': '6',\n",
    "                    'S': '5'}\n",
    "\n",
    "dict_int_to_char = {'0': 'O',\n",
    "                    '1': 'I',\n",
    "                    '3': 'J',\n",
    "                    '4': 'A',\n",
    "                    '6': 'G',\n",
    "                    '5': 'S'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "256e5b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# license_complies_format is a function that checks if the license plate complies with the specified format.\n",
    "# In this case the format is `[A-Z][A-Z][0-9][0-9][A-Z][A-Z][A-Z]`.\n",
    "# We can change this format for specific use cases. For example, now it is configured for UK number plates. We can change the format according to Nepali number plates for our use.\n",
    "# The above character conversion comes handy in this situation where if we are sure that in the second letter of our text we should get a string then if our OCR Reader reads a integer that looks similar to a alphabet maybe 4 then we can neglect the '4 and read 'A' instead.\n",
    "def license_complies_format(text):\n",
    "    # It returnsTrue if the license plate complies with the format, False otherwise.\n",
    "    if len(text) != 7:\n",
    "        return False\n",
    "\n",
    "    if (text[0] in string.ascii_uppercase or text[0] in dict_int_to_char.keys()) and \\\n",
    "       (text[1] in string.ascii_uppercase or text[1] in dict_int_to_char.keys()) and \\\n",
    "       (text[2] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[2] in dict_char_to_int.keys()) and \\\n",
    "       (text[3] in ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'] or text[3] in dict_char_to_int.keys()) and \\\n",
    "       (text[4] in string.ascii_uppercase or text[4] in dict_int_to_char.keys()) and \\\n",
    "       (text[5] in string.ascii_uppercase or text[5] in dict_int_to_char.keys()) and \\\n",
    "       (text[6] in string.ascii_uppercase or text[6] in dict_int_to_char.keys()):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23f45c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_license(text):\n",
    "    license_plate_ = ''\n",
    "    mapping = {0: dict_int_to_char, 1: dict_int_to_char, 4: dict_int_to_char, 5: dict_int_to_char, 6: dict_int_to_char,\n",
    "               2: dict_char_to_int, 3: dict_char_to_int}\n",
    "    for j in [0, 1, 2, 3, 4, 5, 6]:\n",
    "        if text[j] in mapping[j].keys():\n",
    "            license_plate_ += mapping[j][text[j]]\n",
    "        else:\n",
    "            license_plate_ += text[j]\n",
    "\n",
    "    return license_plate_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e4e320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageToWordModel(OnnxInferenceModel):\n",
    "    def __init__(self, char_list, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.char_list = char_list\n",
    "\n",
    "    def predict(self, image):\n",
    "        image = cv.resize(image, self.input_shape[:2][::-1])\n",
    "        image_pred = np.expand_dims(image, axis=0).astype(np.float32)\n",
    "        preds = self.model.run(None, {self.input_name: image_pred})[0]\n",
    "        text = ctc_decoder(preds, self.char_list)[0]\n",
    "        text = text.replace(\" \", \"\")\n",
    "        text = text.replace(\"_\", \"\")\n",
    "        text = text.upper()\n",
    "        if license_complies_format(text):\n",
    "            # bring text into the default license plate format\n",
    "            return format_license(text)\n",
    "        \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efe44e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_to_word_model = ImageToWordModel(model_path=\"C:/Users/avint/Desktop/model.onnx\", char_list=\"0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06f94d71-02bf-4e2a-a26d-d40a3f23c0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_model = YOLO('yolov8n.pt')\n",
    "np_model = YOLO('../model/runs/detect/train/weights/best.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af7ff61",
   "metadata": {},
   "source": [
    "The input video is read by glob. Glob is a function that returns all the pathnames matching a pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a9ba96b-b65c-41e0-9e1f-686cbc72498b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./inputs/sample.mp4']\n"
     ]
    }
   ],
   "source": [
    "videos = glob('./inputs/sample.mp4')\n",
    "print(videos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e14b2-b6ab-436f-a404-9274d63b832c",
   "metadata": {},
   "source": [
    "### STEP 1 Implementing the Car Detection\n",
    "\n",
    "Get the bounding boxes of all vehicles in our video recording with prediction confidence score and object tracking ID"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6603a3",
   "metadata": {},
   "source": [
    "This code currently gathers all the bounding boxes for vehicles in the video and stores them in the `vehicle_bounding_boxes` list. Along with the bounding box coordinates, this list also includes the tracking ID assigned to each identified vehicle. The tracking ID remains consistent from frame to frame, serving as a unique identifier. Additionally, the score indicates the model's confidence level that the particular bounding box indeed contains a vehicle, with values ranging from 0 to 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85cb3c7-8114-476e-8e73-7b00329ca211",
   "metadata": {},
   "source": [
    "### STEP 2 Implementing the License Plate Detection\n",
    "\n",
    "Use the bounding box for each vehicle and use the number plate detector model to try to find the corresponding plate within in the confinement of those boxes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65eec109-ee23-4ca7-8cfb-98410977bfa5",
   "metadata": {},
   "source": [
    "### STEP 3 Preprocess License Plates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f9a846-787b-4c1c-841a-f1afbe356820",
   "metadata": {},
   "source": [
    "### STEP 4 Read License Plates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8cfc75d9-2b40-4379-a765-5ab395be17b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_csv is a function that writes the obtained results to a CSV file using the specified format.\n",
    "# Here we are formatting the colunms as [frame_number, track_id, car_bbox, car_bbox_score, license_plate_bbox, license_plate_bbox_score, license_plate_number, license_text_score].\n",
    "# car_bbox and license_plate_bbox has 4 array that stores the coordinate of the bounding box.\n",
    "\n",
    "def write_csv(results, output_path):\n",
    "    \n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('{},{},{},{},{},{},{},{}\\n'.format(\n",
    "            'frame_number', 'track_id', 'car_bbox', 'car_bbox_score',\n",
    "            'license_plate_bbox', 'license_plate_bbox_score', 'license_plate_number',\n",
    "            'license_text_score'))\n",
    "\n",
    "        for frame_number in results.keys():\n",
    "            for track_id in results[frame_number].keys():\n",
    "                print(results[frame_number][track_id])\n",
    "                if 'car' in results[frame_number][track_id].keys() and \\\n",
    "                   'license_plate' in results[frame_number][track_id].keys() and \\\n",
    "                   'number' in results[frame_number][track_id]['license_plate'].keys():\n",
    "                    f.write('{},{},{},{},{},{},{},{}\\n'.format(\n",
    "                        frame_number,\n",
    "                        track_id,\n",
    "                        '[{} {} {} {}]'.format(\n",
    "                            results[frame_number][track_id]['car']['bbox'][0],\n",
    "                            results[frame_number][track_id]['car']['bbox'][1],\n",
    "                            results[frame_number][track_id]['car']['bbox'][2],\n",
    "                            results[frame_number][track_id]['car']['bbox'][3]\n",
    "                        ),\n",
    "                        results[frame_number][track_id]['car']['bbox_score'],\n",
    "                        '[{} {} {} {}]'.format(\n",
    "                            results[frame_number][track_id]['license_plate']['bbox'][0],\n",
    "                            results[frame_number][track_id]['license_plate']['bbox'][1],\n",
    "                            results[frame_number][track_id]['license_plate']['bbox'][2],\n",
    "                            results[frame_number][track_id]['license_plate']['bbox'][3]\n",
    "                        ),\n",
    "                        results[frame_number][track_id]['license_plate']['bbox_score'],\n",
    "                        results[frame_number][track_id]['license_plate']['number'],\n",
    "                        results[frame_number][track_id]['license_plate']['text_score'])\n",
    "                    )\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b587a8-7354-48ab-ba97-51065643e73a",
   "metadata": {},
   "source": [
    "### STEP 5 Clean-Up License Plate Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cf71cc",
   "metadata": {},
   "source": [
    "This returns a list with bounding box metrics for every frame with a successful detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "28333643-6ef1-449a-bdd0-07d4a8c17e71",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 384x640 2 persons, 3 cars, 71.8ms\n",
      "Speed: 2.8ms preprocess, 71.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[885.9718017578125, 259.9759216308594, 1918.0755615234375, 1069.1480712890625, 1.0, 0.9230321049690247]\n",
      "\n",
      "0: 384x640 1 License_Plate, 66.9ms\n",
      "Speed: 4.2ms preprocess, 66.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[0.256805419921875, 368.2144470214844, 288.8199768066406, 804.2828369140625, 2.0, 0.8570149540901184]\n",
      "\n",
      "0: 384x640 1 License_Plate, 74.3ms\n",
      "Speed: 1.3ms preprocess, 74.3ms inference, 5.7ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 37\u001b[0m\n\u001b[0;32m     35\u001b[0m plate \u001b[38;5;241m=\u001b[39m roi[\u001b[38;5;28mint\u001b[39m(plate_y1):\u001b[38;5;28mint\u001b[39m(plate_y2), \u001b[38;5;28mint\u001b[39m(plate_x1):\u001b[38;5;28mint\u001b[39m(plate_x2)]\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m# cv.imwrite('outputs/plates/roi/'+str(track_id)+ '.jpg', plate)\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m prediction_text \u001b[38;5;241m=\u001b[39m \u001b[43mimage_to_word_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mplate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# if plate could be read write results\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prediction_text \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[6], line 7\u001b[0m, in \u001b[0;36mImageToWordModel.predict\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[1;32m----> 7\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_shape\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     image_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(image, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m      9\u001b[0m     preds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28;01mNone\u001b[39;00m, {\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_name: image_pred})[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "# read video by index\n",
    "video = cv.VideoCapture(videos[0])\n",
    "\n",
    "ret = True\n",
    "frame_number = -1\n",
    "vehicles = [2,3,5]\n",
    "\n",
    "# read the entire video\n",
    "while ret:\n",
    "    ret, frame = video.read()\n",
    "    frame_number += 1\n",
    "    if ret:\n",
    "        results[frame_number] = {}\n",
    "        \n",
    "        # vehicle detector\n",
    "        detections = coco_model.track(frame, persist=True)[0]\n",
    "        for detection in detections.boxes.data.tolist():\n",
    "            x1, y1, x2, y2, track_id, score, class_id = detection\n",
    "            if int(class_id) in vehicles and score > 0.5:\n",
    "                vehicle_bounding_boxes = []\n",
    "                vehicle_bounding_boxes.append([x1, y1, x2, y2, track_id, score])\n",
    "                for bbox in vehicle_bounding_boxes:\n",
    "                    print(bbox)\n",
    "                    roi = frame[int(y1):int(y2), int(x1):int(x2)]\n",
    "                    \n",
    "                    # license plate detector for region of interest\n",
    "                    license_plates = np_model(frame)[0]\n",
    "                    # process license plate\n",
    "                    for license_plate in license_plates.boxes.data.tolist():\n",
    "                        plate_x1, plate_y1, plate_x2, plate_y2, plate_score, _ = license_plate\n",
    "                        # crop plate from region of interest\n",
    "                        # plate = roi[int(plate_y1+30):int(plate_y2-30), int(plate_x1+10):int(plate_x2-10)]\n",
    "                        plate = roi[int(plate_y1):int(plate_y2), int(plate_x1):int(plate_x2)]\n",
    "                        # cv.imwrite('outputs/plates/roi/'+str(track_id)+ '.jpg', plate)\n",
    "                        prediction_text = image_to_word_model.predict(plate)\n",
    "                        # if plate could be read write results\n",
    "                        if prediction_text is not None:\n",
    "                            results[frame_number][track_id] = {\n",
    "                                'car': {\n",
    "                                    'bbox': [x1, y1, x2, y2],\n",
    "                                    'bbox_score': score\n",
    "                                },\n",
    "                                'license_plate': {\n",
    "                                    'bbox': [plate_x1, plate_y1, plate_x2, plate_y2],\n",
    "                                    'bbox_score': plate_score,\n",
    "                                    'number': prediction_text,\n",
    "                                    'text_score': 1.0\n",
    "                                }\n",
    "                            }\n",
    "\n",
    "write_csv(results, './outputs/resultsIMG.csv')\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f3497-c3c7-4a26-b0ef-95f471e6a1a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frame_number</th>\n",
       "      <th>track_id</th>\n",
       "      <th>car_bbox</th>\n",
       "      <th>car_bbox_score</th>\n",
       "      <th>license_plate_bbox</th>\n",
       "      <th>license_plate_bbox_score</th>\n",
       "      <th>license_plate_number</th>\n",
       "      <th>license_text_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [frame_number, track_id, car_bbox, car_bbox_score, license_plate_bbox, license_plate_bbox_score, license_plate_number, license_text_score]\n",
       "Index: []"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = pd.read_csv('./outputs/resultsIMG.csv')\n",
    "\n",
    "# show results for tracking ID `1` - sort by OCR prediction confidence\n",
    "results[results['track_id'] == 1.].sort_values(by='license_text_score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb90d96c-211b-4a64-a7b5-4e41cb0a5328",
   "metadata": {},
   "source": [
    "### STEP 6 Visualize the Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4dc5ede-9ef6-495a-a0f9-fd0f6f51bc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_border(img, top_left, bottom_right, color=(0, 255, 0), thickness=6, line_length_x=200, line_length_y=200):\n",
    "    x1, y1 = top_left\n",
    "    x2, y2 = bottom_right\n",
    "\n",
    "    cv.line(img, (x1, y1), (x1, y1 + line_length_y), color, thickness)  #-- top-left\n",
    "    cv.line(img, (x1, y1), (x1 + line_length_x, y1), color, thickness)\n",
    "\n",
    "    cv.line(img, (x1, y2), (x1, y2 - line_length_y), color, thickness)  #-- bottom-left\n",
    "    cv.line(img, (x1, y2), (x1 + line_length_x, y2), color, thickness)\n",
    "\n",
    "    cv.line(img, (x2, y1), (x2 - line_length_x, y1), color, thickness)  #-- top-right\n",
    "    cv.line(img, (x2, y1), (x2, y1 + line_length_y), color, thickness)\n",
    "\n",
    "    cv.line(img, (x2, y2), (x2, y2 - line_length_y), color, thickness)  #-- bottom-right\n",
    "    cv.line(img, (x2, y2), (x2 - line_length_x, y2), color, thickness)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b9090-63d4-402e-bf6e-e25cb42e31cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read video by index\n",
    "video = cv.VideoCapture(videos[0])\n",
    "\n",
    "# get video dims\n",
    "frame_width = int(video.get(3))\n",
    "frame_height = int(video.get(4))\n",
    "size = (frame_width, frame_height)\n",
    "\n",
    "# Define the codec and create VideoWriter object\n",
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv.VideoWriter('./outputs/processedIMG.mp4', fourcc, 20.0, size)\n",
    "\n",
    "# reset video before you re-run cell below\n",
    "frame_number = -1\n",
    "video.set(cv.CAP_PROP_POS_FRAMES, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03075f2-02ad-4d90-8d4a-569ea90c2588",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ret = True\n",
    "\n",
    "while ret:\n",
    "    ret, frame = video.read()\n",
    "    frame_number += 1\n",
    "    if ret:\n",
    "        df_ = results[results['frame_number'] == frame_number]\n",
    "        for index in range(len(df_)):\n",
    "            # draw car\n",
    "            vhcl_x1, vhcl_y1, vhcl_x2, vhcl_y2 = ast.literal_eval(df_.iloc[index]['car_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "            \n",
    "            draw_border(\n",
    "                frame, (int(vhcl_x1), int(vhcl_y1)),\n",
    "                (int(vhcl_x2), int(vhcl_y2)), (0, 255, 0),\n",
    "                12, line_length_x=200, line_length_y=200)\n",
    "            \n",
    "            # draw license plate\n",
    "            plate_x1, plate_y1, plate_x2, plate_y2 = ast.literal_eval(df_.iloc[index]['license_plate_bbox'].replace('[ ', '[').replace('   ', ' ').replace('  ', ' ').replace(' ', ','))\n",
    "\n",
    "            # region of interest for license plate\n",
    "            roi = frame[int(vhcl_y1):int(vhcl_y2), int(vhcl_x1):int(vhcl_x2)]\n",
    "            cv.rectangle(roi, (int(plate_x1), int(plate_y1)), (int(plate_x2), int(plate_y2)), (0, 0, 255), 6)\n",
    "            #endregion\n",
    "            # write detected number\n",
    "            (text_width, text_height), _ = cv.getTextSize(\n",
    "                df_.iloc[index]['license_plate_number'],\n",
    "                cv.FONT_HERSHEY_SIMPLEX,\n",
    "                2,\n",
    "                6)\n",
    "\n",
    "            cv.putText(\n",
    "                frame,\n",
    "                df_.iloc[index]['license_plate_number'],\n",
    "                (int((vhcl_x2 + vhcl_x1 - text_width)/2), int(vhcl_y1 - text_height)),\n",
    "                cv.FONT_HERSHEY_SIMPLEX,\n",
    "                2,\n",
    "                (0, 255, 0),\n",
    "                6\n",
    "            )\n",
    "\n",
    "        out.write(frame)\n",
    "        frame = cv.resize(frame, (1280, 720))\n",
    "\n",
    "out.release()\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fce7a8-79b5-48af-ab2d-f590bd0bdc9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  license_plate_number  track_id  license_text_score\n",
      "3              TE60EIT      23.0                 2.0\n",
      "2              RO05AMR      35.0                 1.0\n",
      "0              IS55ESM      51.0                 2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming your input data is stored in a CSV file named 'data.csv'\n",
    "# You can adjust the file name or provide the data directly if it's not in a file\n",
    "data = pd.read_csv('./outputs/resultsIMG.csv')\n",
    "\n",
    "# Convert 'license_text_score' to numeric\n",
    "data['license_text_score'] = pd.to_numeric(data['license_text_score'], errors='coerce')\n",
    "\n",
    "# Calculate the total sum of license_text_score for each license_plate_number\n",
    "total_license_score = data.groupby('license_plate_number')['license_text_score'].sum()\n",
    "\n",
    "# Find the row with the maximum license_plate_score for each license_plate_number\n",
    "max_license_score_row = data.loc[data.groupby('license_plate_number')['license_text_score'].idxmax()]\n",
    "\n",
    "# Merge the two DataFrames on license_plate_number\n",
    "result = pd.merge(max_license_score_row[['license_plate_number', 'track_id']], total_license_score.reset_index(),\n",
    "                  on='license_plate_number', how='inner')\n",
    "\n",
    "# Find the row with the maximum license_text_score for each track_id\n",
    "max_license_score_row = result.loc[result.groupby('track_id')['license_text_score'].idxmax()]\n",
    "\n",
    "# Display the result\n",
    "print(max_license_score_row)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
